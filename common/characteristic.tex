
{\actuality} 
В огромном количестве прикладных задач возникает необходимость в подходящих алгоритмах непрерывной оптимизации. Очень важна эффективность применения тех или иных методов нахождения оптимального решения. В широком смысле под эффективностью понимается время, необходимое для получения достаточно хорошего решения. Однако, подобный параметр зависит от огромного количества аспектов, не имеющих прямого отношения к алгоритму поиска достаточно хорошего решения. Такими аспектами могут являться мощность вычислительного устройства, доступная точность представления чисел, необходимое количество памяти и т.д. Чтобы разделить технический и теоретический аспекты под эффективностью метода на определенном классе задач (набор задач объединенных некоторой характеристикой) часто понимают именно эффективность (оптимальность) в смысле Бахвалова-Немировского[] --- число обращений по ходу работы метода к \textit{оракулу}. Оракулом называется подпрограмма расчета значений целевой функции (градиента или иных метрик более высокого порядка) с необходимой точностью.

Таким образом аналитическая сложность оптимизационной задачи для метода на заданном классе характеризуется необходимым количеством запросов к оракулу для нахождения приближенного решения с заранее заданной точностью $\varepsilon > 0$.

Задачи гладкой оптимизации являются наиболее теоретически исследованным классом. Лучшие результаты с точки зрения скорости сходимости получены именно на данном классе. [литература] 

Однако на практике зачастую нет возможности проверить наличие гладкости или она отсутствует из-за специфики исследуемого функционала. Во многих областях, таких как машинное обучение, анализ данных, оценка риска и некоторые физические приложения возникают функционалы не обладающие достаточными свойствами для эффективной их минимизации методами гладкой оптимизации. По данной причине достаточно актуальны вопросы разработки эффективных методов для работы в негладкой постановке. 

Также стоит отметить тенденцию к повышению размерности решаемых задач. С ростом популярности нейронных сетей возросла необходимость в алгоритмах продолжающих работать столь же эффективно при повышении размерности. Классической альтернативой для негладких случаев выступают методы первого порядка (субградиентные методы), но они уже не имеют столь же высоких гарантий скорости. Существует несколько подходов к данной проблеме, например выделение специальных подклассов, таких как условие острого минимума, предложенное в конце 1960-х годов Б.Т. Поляком. Стоит подчеркнуть, что подобные условия зачастую выставляют более жесткие требования к задаче, например, острый минимум подразумевает доступность минимального значения функции. 

В связи с этим возникает альтернативное направление в виде обобщения условий в оптимальных методах, обладающих приемлемой скоростью сходимости. Также стоит упомянуть, что градиентные методы получили распространение после роста  востребованности задач большой размерности. Использовавшиеся ранее методы внутренней точки имели существенную зависимость от размерности задачи. В связи с этими аспектами возникает естественное желание воспользоваться рядом значимых результатов, таких как оптимальная оценка скорости сходимости на классе липшицевых и сильно выпуклых минимизационных задач, которая достигается именно для субградиентного метода \cite{Simon_Julien_Bach_2012} для более широкого класса задач. Методы данного типа обладают небольшими затратами памяти на итерациях и не столь зависимы от размерности задачи. 

Многие прикладные задачи обладают сложной внутренней структурой, которая не позволяет применять к ним методы оптимизации <<из коробки>>, иначе говоря в исходном теоретическом виде. С ростом популярности нейронных сетей, повышением сложности экономических моделей, развитием компиляторных оптимизаций все чаще происходит столкновение с задачей распределения ресурсов в различной форме и с существенным набором специальных ограничений, усложняет работу плохо определенные минимизируемые функционалы (различные loss-функции, к примеру). Многие из упомянутых задач не обладают выпуклостью, не говоря уже о гладкости. В подобной постановке список возможных методов сильно ограничен,  речь уже не идет о хороших оценках, встает вопрос о простой сходимости. Значительную роль играет проблема роста размерности, например при использовании <<покоординатного спуска>> скорость сходимости пропорциональна $\mathcal{O} (n)$, что значительно хуже градиентных аналогов. В связи с чем возникает естественное желание расширить класс задач для которых можно применять хорошо исследованные методы первого порядка. 

  Также получила широкое распространение методика приближения к некоторому гладкому аналогу целевой выпуклой функции. Эту идею используют известные универсальные методы в таких работах как []. Универсальные градиентные методы основаны на квадратичной интерполяции короче чего-то для выпуклых функций с гелдеровыми градиентом, они используют погрешность для подсройки контанты гельдера. Универсальность в данном случае подразумевает подстройку под гладкость функции. К подобным подходам, когда пытаются выделить некоторые локальные свойства функции и подстроится к ее локальным параметрам можно отнести квазиньютоновские методы, однако они оперируют параметрами более высокого порядка. 

  Если проанализировать теоремы об оптимальных оценках для различных методов первого порядка, то можно обнаружить, что ряд свойств, которые требуются для достижения данной оценки, позволяют релаксацию, что и привело к появлению ряда работ[], которые переходят к <<относительной липшицевости>> и постановке задачи в терминах вариационных неравенств. Подобный подход будет развит в последующих главах, здесь мы не будем останавливаться на данном направлении.

  Стоит отметить, что подобная формулировка оценки через количество обращений к оракулу(подпрограмме) удобна для сравнения методов, однако если анализировать вопрос с точки зрения имплементации, то возникнут определенные несоответсвия. Алгоритмическая сложность не учитывает ряда особенностей самого метода, как и возможностей вычислительного устройства на котором будут происходить измерения. Например, в оценке никак не отражается зависимость по данным в алгоритме, что напрямую определяет возможности параллелизации алгоритма. Причем тип и параметры параллелизации будут зависеть, как от алгоритма, так и от организации памяти и иных функциональных ограничений устройства. Попытка сгладить явную непотимальность покоординатного спуска за счет реализации была предпринята при работе с физически определенным значительно невыпуклым функционалом. Результаты данного исследования вошли в данную главу. 

  Также стоит упомянуть о схожих проблемах, возникающих при работе с распределенной оптимизацией, поскольку возникает необходимость передачи информации о решаемой задаче другим вычисляющим устройствам, объединенным в определенную топологию. В частности большой популярностью в данных задачах пользуются Стохастические варианты методов, что легко объясняется их структурой. 

  Рассуждая об имплементации методов оптимизации стоит также принимать в расчет ограничения, возникающие из-за машинного представления чисел. Во многих случаях недостаточная точность может приводить к так называемым градиентным взрывам или исчезновению значения, что соответствует слишком большому для представления числу и слишком малому для отделения его от 0. Данные аспекты можно отразить при помощи концепции неточного оракула, что в конечном итоге также влияет на оценки. Также можно попытаться обнаружить ошибку и исправить ее, или просто отбросить подобное значение. Тут важно отметить, что машинная точность необходимая для работы метода является существенным ограничением для его использования в различных приложениях. Чем выше требуемая точность, тем больше необходимо памяти для хранения результатов работы, тем более сложное представление чисел необходимо поддерживать. Практическим примером подобной проблематики является процесс переноса обучения нейронной сети с серверных мощностей на устройство со значительным ограничением памяти, такое как мобильный телефон. 

  Исследуется хорошо известная оптимальная оценка скорости сходимости на классе липшицевых и сильно выпуклых минимизационных, которая достигается именно для субградиентного метода \cite{Simon_Julien_Bach_2012}. Доказывается уточненная версия данной оценки при помощи перехода от глобальных констант к локальным аналогам, что позволяет сделать ее более адаптивной и удобной для практического применения. 

  Также используется подход, набравший популярность в последние годы, а именно обобщение на случай задачи с аналогом условия Липшица относительно некоторой выпуклой прокс-функции (относительная липшицевость), которая, в отличие от классической постановки, не обязана удовлетворять условию сильной выпуклости относительно нормы \cite{AdaMirr_2021,Lu_2018,Zhou_NIPS_2020}. Мы исследуем оценку скорости сходимости субградиентного метода для сильно выпуклых задач с аналогичным предположением об относительной липшицевости. Точнее говоря, в данной главе рассматривается вариант субградиентного метода на классе относительно ограниченных и относительно сильно монотонных вариационных неравенств, а также класс относительно сильно выпукло-вогнутых седловых задач с соответствующими условиями относительной липшицевости функционалов. 

  Далее, немалую популярность в работах по оптимизации получило упомянутое выше недавно предложенное понятие относительной гладкости функций (см. работы \cite{Bauschke,Drag,Dragomir,Lu_Nesterov_2018}, а также приведённые в них ссылки), которое позволило существенно расширить класс задач выпуклой оптимизации по сравнению со стандартным предположением о липшицевости градиента с гарантией оценки скорости сходимости $O(N^{-1})$ (здесь и далее $N$ --- количество итераций), которая может считаться оптимальной для такого широкого класса задач \cite{Dragomir}. 

  Работа состоит из введения, трех основных частей (пунктов) и заключения. Второй пункт статьи посвящён модификации метода зеркального спуска и выводу оценки его скорости сходимости для вариационных неравенств с относительно сильно монотонными и относительно ограниченными операторами. В частности, полученная оценка указывает на оптимальность такого метода на выделенном классе вариационных неравенств, поскольку она оптимальна (с точностью до умножения на не зависящую от параметров метода и размерности пространства константу) даже на более узком классе задач минимизации относительно липшицевых и относительно сильно выпуклых функций \cite{Lu_2018}. В третьем пункте статьи рассматривается класс относительно сильно монотонных и относительной гладких операторов и анализируется возможность использования рестартованного адаптивного проксимального зеркального метода для такого класса задач с обоснованием гарантии линейной скорости сходимости. В четвертом пункте показывается, как предложенные ранее алгоритмы для вариационных неравенств и полученные теоретические оценки их скорости сходимости могут быть применены для решения относительно сильно выпукло-вогнутых седловых задач с соответствующими предположениями о гладкости функционалов.

  \begin{table}[h]
    \caption{Сравнение характеристик методов}
    \label{tabular:timesandtenses}
    \centering
    \resizebox{\textwidth}{!}{
        \begin{tabular}{|c|c|c|}
            \hline
            \fontsize{12pt}{12pt}\selectfont {\bfseries Показатели} & {\bfseries ``Шевеление'' атома} & {\bfseries Адаптивный градиентный спуск} \\
            \hline
            \fontsize{12pt}{12pt}\selectfont Время 1 итерации, секунды    & 1.2075 & 122.9814 \\
            \hline
            \fontsize{12pt}{12pt}\selectfont Энергия 1 итерации, кДж/моль & 0.0225 & 2.7081 \\
            \hline
            \fontsize{12pt}{12pt}\selectfont $\sim\Delta$Энергии к 300 минуте, кДж/моль & $- 347$ & $- 413$ \\
            \hline
        \end{tabular}
    }
\end{table}

% {\progress}
% Этот раздел должен быть отдельным структурным элементом по
% ГОСТ, но он, как правило, включается в описание актуальности
% темы. Нужен он отдельным структурынм элемементом или нет ---
% смотрите другие диссертации вашего совета, скорее всего не нужен.

{\aim} данной работы является исследование и совершенствование методов оптимизации для задач, не обладающих достаточной гладкостью для применения классических методов. Подобные задачи возникают в различных областях, таких как белковый фолдинг и машинное обучение. Каждая из исследуемых задач также имеет большую размерность. В данной работе автор пытается расширить доступный класс задач и предложить подходы, отходящие от классического определения гладкости, сохраняя при этом соответствующую скорость сходимости. Также в работе применяются различные техники ускорения субградиентных методов, доказываются соответствующие теоремы сходимости и проводятся соответствующие численные эксперименты. Также сделан существенный акцент на экспериментальной составляющей. 

{\novelty}
\begin{enumerate}[beginpenalty=10000] % https://tex.stackexchange.com/a/476052/104425
  \item Впервые сформулированы и доказаны оценки для метода зеркального спуска для вариационных неравенств с относительно сильно монотонными и относительно ограниченными операторами.
  \item Впервые сформулированы и доказаны оценки скорости сходимости рестартованного метода зеркального спуска для относительно липшицевых задач оптимизации с относительным $\gamma$-ростом.
  \item Было выполнено оригинальное исследование для уточнения оптимальных оценок зеркального спуска для задач минимизации сильно выпуклых функций с использованием локальных аналогов константы Липшица, что позволило получить обобщение на случай относительно липшицевой постановки. 
\end{enumerate}

{\defpositions}
\begin{enumerate}[beginpenalty=10000] % https://tex.stackexchange.com/a/476052/104425
  \item Предложен вариант метода зеркального спуска для вариационных неравенств с относительно сильно монотонными и относительно ограниченными операторами. Доказана инвариантная по размерности пространства оценка скорости сходимости этого метода, оптимальная на указанном классе задач с точностью до умножения на постоянный множитель.
  \item Получена адаптивная оценка скорости сходимости зеркального спуска для задач минимизации сильно выпуклых функций с использованием локальных аналогов константы Липшица. При этом сохраняется оптимальность этой оценки на классе сильно выпуклых липшицевых задач с точностью до умножения на константу. В частности, это позволяет работать с нелипшицевыми задачами.(относительно липшицевыми)
  \item Введён аналог ослабленного минимума ($\gamma$-роста) с использованием дивергенции Брэгмана. Получена оценка скорости сходимости рестартованного метода зеркального спуска для относительно липшицевых задач оптимизации с относительным $\gamma$-ростом. В ситуации сильно выпуклой прокс-функции предложены адаптивные правила остановки для рестартов исследуемого метода зеркального спуска и получены оценки его скорости сходимости.
\end{enumerate}

{\probation}
Основные результаты работы докладывались~на:
перечисление основных конференций, симпозиумов и~т.\:п.

{\contribution} Ключевые результаты получены и доказаны автором лично. Также разработана библиотека для анализа и проверки методов оптимизации, обеспечивающая необходимую гибкость настройки. 

\ifnumequal{\value{bibliosel}}{0}
{%%% Встроенная реализация с загрузкой файла через движок bibtex8. (При желании, внутри можно использовать обычные ссылки, наподобие `\cite{vakbib1,vakbib2}`).
    {\publications} Основные результаты по теме диссертации изложены
    в~XX~печатных изданиях,
    X из которых изданы в журналах, рекомендованных ВАК,
    X "--- в тезисах докладов.
}%
{%%% Реализация пакетом biblatex через движок biber
    \begin{refsection}[bl-author, bl-registered]
        % Это refsection=1.
        % Процитированные здесь работы:
        %  * подсчитываются, для автоматического составления фразы "Основные результаты ..."
        %  * попадают в авторскую библиографию, при usefootcite==0 и стиле `\insertbiblioauthor` или `\insertbiblioauthorgrouped`
        %  * нумеруются там в зависимости от порядка команд `\printbibliography` в этом разделе.
        %  * при использовании `\insertbiblioauthorgrouped`, порядок команд `\printbibliography` в нём должен быть тем же (см. biblio/biblatex.tex)
        %
        % Невидимый библиографический список для подсчёта количества публикаций:
        \printbibliography[heading=nobibheading, section=1, env=countauthorvak,          keyword=biblioauthorvak]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorwos,          keyword=biblioauthorwos]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorscopus,       keyword=biblioauthorscopus]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorconf,         keyword=biblioauthorconf]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorother,        keyword=biblioauthorother]%
        \printbibliography[heading=nobibheading, section=1, env=countregistered,         keyword=biblioregistered]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorpatent,       keyword=biblioauthorpatent]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorprogram,      keyword=biblioauthorprogram]%
        \printbibliography[heading=nobibheading, section=1, env=countauthor,             keyword=biblioauthor]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorvakscopuswos, filter=vakscopuswos]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorscopuswos,    filter=scopuswos]%
        %
        \nocite{*}%
        %
        {\publications} Основные результаты по теме диссертации изложены в~\arabic{citeauthor}~печатных изданиях,
        \arabic{citeauthorvak} из которых изданы в журналах, рекомендованных ВАК\sloppy%
        \ifnum \value{citeauthorscopuswos}>0%
            , \arabic{citeauthorscopuswos} "--- в~периодических научных журналах, индексируемых Web of~Science и Scopus\sloppy%
        \fi%
        \ifnum \value{citeauthorconf}>0%
            , \arabic{citeauthorconf} "--- в~тезисах докладов.
        \else%
            .
        \fi%
        \ifnum \value{citeregistered}=1%
            \ifnum \value{citeauthorpatent}=1%
                Зарегистрирован \arabic{citeauthorpatent} патент.
            \fi%
            \ifnum \value{citeauthorprogram}=1%
                Зарегистрирована \arabic{citeauthorprogram} программа для ЭВМ.
            \fi%
        \fi%
        \ifnum \value{citeregistered}>1%
            Зарегистрированы\ %
            \ifnum \value{citeauthorpatent}>0%
            \formbytotal{citeauthorpatent}{патент}{}{а}{}\sloppy%
            \ifnum \value{citeauthorprogram}=0 . \else \ и~\fi%
            \fi%
            \ifnum \value{citeauthorprogram}>0%
            \formbytotal{citeauthorprogram}{программ}{а}{ы}{} для ЭВМ.
            \fi%
        \fi%
        % К публикациям, в которых излагаются основные научные результаты диссертации на соискание учёной
        % степени, в рецензируемых изданиях приравниваются патенты на изобретения, патенты (свидетельства) на
        % полезную модель, патенты на промышленный образец, патенты на селекционные достижения, свидетельства
        % на программу для электронных вычислительных машин, базу данных, топологию интегральных микросхем,
        % зарегистрированные в установленном порядке.(в ред. Постановления Правительства РФ от 21.04.2016 N 335)
    \end{refsection}%
    \begin{refsection}[bl-author, bl-registered]
        % Это refsection=2.
        % Процитированные здесь работы:
        %  * попадают в авторскую библиографию, при usefootcite==0 и стиле `\insertbiblioauthorimportant`.
        %  * ни на что не влияют в противном случае
        % \nocite{vakbib2}%vak
        % \nocite{patbib1}%patent
        % \nocite{progbib1}%program
        % \nocite{bib1}%other
        % \nocite{confbib1}%conf
    \end{refsection}%
        %
        % Всё, что вне этих двух refsection, это refsection=0,
        %  * для диссертации - это нормальные ссылки, попадающие в обычную библиографию
        %  * для автореферата:
        %     * при usefootcite==0, ссылка корректно сработает только для источника из `external.bib`. Для своих работ --- напечатает "[0]" (и даже Warning не вылезет).
        %     * при usefootcite==1, ссылка сработает нормально. В авторской библиографии будут только процитированные в refsection=0 работы.
}

